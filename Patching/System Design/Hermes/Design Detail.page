- 在任何实时数据同步和复制中，需要考虑如下几个关键问题：
    - 事务一致性：在复制目标端需要按照源端相同的事务环境进行提交，确保目标上数据一致性。
    - 检查点机制：在抽取和负责时都需要记录检查点位置，确保网络故障或GG本身故障下仍然能够完整复制。
    - 可靠数据传输：需要保证数据传输的完整性，请求和应答，同时提供数据加密和传输过程中的压缩。

- SCN如何保证数据一致性

- 关于多线程的考虑
    - 现在考虑到logminer的视图常驻内存，且实时追踪DB变化，没必要在数据库连接池中放大量连接，所以暂时放3个，来针对可能的比较高频率的在三个redolog间进行切换的重新连接
    - 假设我们使用的是多核机器， 如果最终hermes能够处理 10w/s的更新，那么在logminer向sqlContainer这一端其实是相对比较耗时的，也就是说很可能会成为一个瓶颈。 syncTask从sqlContainer中拿sql之后进行解析，然后写入hbase这一段似乎并没有那么慢速， 所以可能会考虑在logminer->sqlcontainer之间这一段提速，然而在这一段盲目多线程又是不切实际的(SCN同步的问题), 所以需要考虑在什么时机可以提高并发度，比如在加载完logminer的时候，一个线程进行结果查询， 新开一个线程进行下一轮logminer。
    - 暂且考虑logminer中可以开启多线程，而且每个线程在内存中持有的视图都是单独的不互相影响的。（待考证)

- 目前情况是：
    - 首先Hermes跟Oracle数据库应该不是同一个地方， 那么涉及到一个SQL传输的问题（以及远程操作logminer)
    - Logminer -> Hermes这一段采用单线程（当然待测， 如果测出来效果very Rubbish，需要改善)
    - Hermes -> Hbase之间需要采用多线程， 因为单线程的读写效率比较低， 采用多线程长连接， 然后在保证事务与数据完整性的前提下，尽量进行写合并， 提高这一端的效率。。。
    - 注意到hbase的一个事实是: hbase中实际上是没有更新操作的，所有的更新都变成了写操作

- $\bigstar$ 提高一下代码的层次， 学会专业打Log， 以及专业写Unit Test, 不要太low..

- Hbase的操作合并的可能性方案
    - 开辟三个队列，分别存储put/update/delete
    - put可以多线程操作，upd可以合并也是必然， 然而upd的合并必须要按照scn
    - delete操作貌似也是可以不考虑顺序的？ 因为delete之后就不再考虑这个row啦？然而delete row可以提前? 发现row已经被删除就不必要再继续update或者其他（会不会不能实时反应oracle的变化?)

- Construct a testing Environment
    - Oracle(Thinkpad) -> Hermes(MAC) -> Hbase(Lab's Cluster)

- 腊鸡Hbase
    - 注意使用hbase时的maven包版本问题
    - 将之前的代码重构到hbase的连接池模式下时发现，包的版本问题很大， 于是换了hbase-common的版本， 以及解决了COW包的缺失问题
